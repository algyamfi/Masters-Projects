{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a68f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the libraries necessary to this research\n",
    "\n",
    "#Data Preparation and Analysis\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Data Visualization \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "\n",
    "# NLP Model and Model Analysis\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "\n",
    "# Disable Warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88b1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e9e60",
   "metadata": {},
   "source": [
    "# Part I: Research Question\n",
    "\n",
    "\n",
    "# A1. RESEARCH QUESTION\n",
    "Can Sentiment Analysis be employed as a means to predict the emotional tone of users from the content of their reviews?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A2. OBJECTIVES AND GOALS\n",
    "The goal of this analysis is to develop a robust predictive model capable of accurately forecasting the sentiments expressed in user reviews with a minimum accuracy of 85%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A3. PRESCRIBED NETWORK \n",
    "\n",
    "In this Sentiment Analysis experiment, I have chosen the LSTM network, which stands for Long Short-Term Memory networks. LSTM is a type of Deep Learning model extensively utilized in various applications. It falls under the category of Recurrent Neural Networks (RNNs) and excels at learning long-term dependencies, particularly in sequence prediction tasks. \n",
    "\n",
    "Unlike conventional RNNs, which can struggle with long sequences, LSTM incorporates unique feedback connections, granting it the exceptional capability to process entire sequences of data. This aspect makes LSTM particularly well-suited for tasks involving sequential data, such as text, speech, and time-series data.\n",
    "\n",
    "In the field of Sentiment Analysis, the LSTM network shines brightly, allowing us to analyze and understand the emotions and opinions expressed in user reviews and social media posts. Additionally, LSTM's versatility extends to various other domains, including Language modeling, where it excels in predicting and generating text; Machine translation, where it enables accurate language translation; Handwriting recognition, making it adept at interpreting handwritten text; and Image captioning, enabling it to generate descriptive captions for images (Intellipaat, 2022).\n",
    "\n",
    "Through the remarkable performance and widespread applications of LSTM, it has become a cornerstone of modern Deep Learning and continues to unlock new possibilities in the realm of artificial intelligence.\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# B1. DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9319204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the nltk stopwords package  \n",
    "# Reference I1\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc91dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Review</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Customer Review  Sentiment Score\n",
       "0  So there is no way for me to plug it in here i...                0\n",
       "1                        Good case, Excellent value.                1\n",
       "2                             Great for the jawbone.                1\n",
       "3  Tied to charger for conversations lasting more...                0\n",
       "4                                  The mic is great.                1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "# Reference I2\n",
    "az_data = pd.read_csv('amazon_cells_labelled.txt', header=None, delimiter = \"\\t\", \n",
    "                      names=[\"Customer Review\", \"Sentiment Score\"])\n",
    "\n",
    "# Print Head\n",
    "az_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48555dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Customer Review  1000 non-null   object\n",
      " 1   Sentiment Score  1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "\n",
    "az_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c5bf4",
   "metadata": {},
   "source": [
    "# Data Preparation \n",
    "\n",
    "\n",
    "\n",
    "# Transform to lower case\n",
    "\n",
    "In this step all review text is converted to lower case. Apart from being essential in the data preprocessing phase, this step \n",
    "is also very important in the later steps of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131824e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower Case Conversion\n",
    "    \n",
    "az_data['Customer Review'] = az_data['Customer Review'].apply(lambda a: a.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a481c980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Review</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case, excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Customer Review  Sentiment Score\n",
       "0  so there is no way for me to plug it in here i...                0\n",
       "1                        good case, excellent value.                1\n",
       "2                             great for the jawbone.                1\n",
       "3  tied to charger for conversations lasting more...                0\n",
       "4                                  the mic is great.                1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify changes\n",
    "    \n",
    "az_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159fad4",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "# Presence of unusual characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c74638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place all unusual characters in a list \n",
    "# Reference I3\n",
    "\n",
    "review_data = az_data['Customer Review'].tolist()\n",
    "\n",
    "uc_data = [\"\".join([a for a in b if not a.isalpha()]) for b in review_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4064d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['                    .', ' ,  .', '   .', '        45 . !!', '   .', '                .', '        ,            .', '    ...   !', '  ,    .', '      !.', '     .', '             .', '        5+             .', '   ', '    ,    \"\"      .', '          .', '      !', '   !.', ' !.', '                .', \"   '     ,        .\", '            !', '     .', \"            '    .\", '             .', '   /  .', \"'     7       '     ' .\", \" '         .\", '                 .', \"'  .\", '       ,     .', '            .', '         .', '             .', '                 . ', '    3                .   .', '     .', '   .', '         680.', ' .', '      2,           .', '      .', '   .', '     .', '  .', '      ', '         ?.', '              .', '    .', '  .']\n"
     ]
    }
   ],
   "source": [
    "# Print list up till 50th index\n",
    "\n",
    "print(uc_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac53c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Review</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Customer Review  Sentiment Score\n",
       "0  so there is no way for me to plug it in here i...                0\n",
       "1                          good case excellent value                1\n",
       "2                              great for the jawbone                1\n",
       "3  tied to charger for conversations lasting more...                0\n",
       "4                                   the mic is great                1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All unusual chars will be removed\n",
    "\n",
    "az_data['Customer Review'] = az_data['Customer Review'].str.replace('[^a-zA-Z\\s]', '')\n",
    "az_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17937ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify whether there are any remaining unusual characters.\n",
    "# Repeat list step\n",
    "\n",
    "review_data = az_data['Customer Review'].tolist()\n",
    "uc_data = [\"\".join([a for a in b if not a.isalpha()]) for b in review_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6e328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['                    ', '   ', '   ', '          ', '   ', '                ', '                    ', '       ', '      ', '      ', '     ', '             ', '                     ', '   ', '              ', '          ', '      ', '   ', ' ', '                ', '                ', '            ', '     ', '                ', '             ', '     ', '                  ', '          ', '                 ', '  ', '            ', '            ', '         ', '             ', '                  ', '                       ', '     ', '   ', '         ', ' ', '                 ', '      ', '   ', '     ', '  ', '      ', '         ', '              ', '    ', '  ']\n"
     ]
    }
   ],
   "source": [
    "# Print list up till 50th index\n",
    "\n",
    "print(uc_data[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee24e9",
   "metadata": {},
   "source": [
    "Apart from commas, the above results indicate that all other unusual characters have been successfully eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64777f51",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Vocabulary Size\n",
    "During the tokenization process in Section B2 below, the vocabulary size is determined to be 1749."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8bb8e",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Proposed Word Embedding Length\n",
    "By applying the \"empirical rule of thumb,\" a word embedded length of 6 was selected for the analysis. The word embedding represents the total number of dimensions used to represent each word in the embedding space. The choice of this length is based on the fourth rule, which is the consideration of all possibilities for embedding dimensions.\n",
    "\n",
    "When selecting the dimensions for word embeddings, there is a trade-off between higher and lower dimensions. Higher dimensions can potentially lead to increased accuracy, but they may also result in an overfit model, where the model performs well on the training data but poorly on new data. On the other hand, lower dimensions can help in reducing the risk of overfitting but might sacrifice some level of accuracy in modeling. Hence, it is crucial to strike a balance and choose the word embedded length that best suits the specific task and dataset to achieve optimal performance in sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8eb1756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.466919462360187"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the 4th root of Vocab size\n",
    "\n",
    "length_ = 1749 ** (1.0 / 4)\n",
    "length_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee49f39",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Statistical Justification for the Chosen Maximum Sequence Length\n",
    "\n",
    "To determine the appropriate amount of padding, I analyzed the summary statistics of the word count in each Customer Review The average number of words was 34, centered around the 54th percentile, indicating that approximately 46% of reviews contained more words than the mean. The longest review had 91 words. Additionally, I examined the 90th, 95th, and 99th percentiles, which had approxiamtely 72, 78, and 88 words, respectively. To ensure that almost all words are captured during padding, I opted to select the 99th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74dbfb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number, of words\n",
    "\n",
    "wrds = az_data['Customer Review'].str.split().apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3792023f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29.000000\n",
       "mean     34.482759\n",
       "std      25.036574\n",
       "min       1.000000\n",
       "25%      16.000000\n",
       "50%      31.000000\n",
       "75%      44.000000\n",
       "max      91.000000\n",
       "Name: Customer Review, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Summary statistics\n",
    "\n",
    "wrds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6fbc564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.60000000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds.quantile(0.54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de6745a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds.quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8928ba76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds.quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a610668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.91999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds.quantile(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685604b",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# B2. TOKENIZATION\n",
    "\n",
    "Tokenization is a significant Natural Language Processing (NLP) task that involves breaking down a given text into smaller units called tokens. These tokens can represent complete words, parts of words, or even individual characters, including punctuation marks. It serves as a foundational step in NLP, facilitating various text processing and analysis tasks (Perry, 2021).\n",
    "\n",
    "Based on the definition above, we can categorize tokenization into three main types: word-level, sub-word-level, and character-level tokenization. For this particular analysis, we will focus on word-level tokenization using the Python Tensorflow library, specifically the tensorflow.keras.preprocessing.text.Tokenizer object. This powerful tool allows us to split a text into distinct words based on a defined delimiter. Each word is then assigned a unique numeric code, which forms the vocabulary for the entire dataset. The Tokenizer dynamically adapts to new words encountered during the process, ensuring a comprehensive representation.\n",
    "\n",
    "Once the tokenization process is complete, the algorithm proceeds to analyze the clusters of tokens for each review text, identifying and grouping together tokens with similar meanings or contexts. This analysis plays a crucial role in subsequent NLP tasks, enabling sentiment analysis, topic modeling, and other language-based insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21e159fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude stop words from Customer Review text \n",
    "# Reference I4\n",
    "\n",
    "sw_ = stopwords.words('english')\n",
    "az_data['Customer Review'] = az_data['Customer Review'].apply(lambda a: ' '.join([w for w in a.split() if w not in (sw_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "786331e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Tokenization Process \n",
    "# Reference I5\n",
    "\n",
    "\n",
    "rv_data = az_data['Customer Review'].values\n",
    "tk = Tokenizer(num_words=5000)\n",
    "tk.fit_on_texts(rv_data)\n",
    "\n",
    "\n",
    "# Vocabulary Size\n",
    "vc = len(tk.word_index) + 1\n",
    "\n",
    "# Encoder\n",
    "enc = tk.texts_to_sequences(rv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d02f7ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1749\n"
     ]
    }
   ],
   "source": [
    "# Print Vocabulary Lenth\n",
    "\n",
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8819372b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impressed going original battery extended battery\n",
      "[97, 154, 182, 8, 439, 8]\n"
     ]
    }
   ],
   "source": [
    "# Print a review text and its encoded data\n",
    "    \n",
    "print(rv_data[11])\n",
    "print(enc[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd5293",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# B3. PADDING PROCESS\n",
    "In the context of neural networks, it is essential for inputs to have consistent shapes and sizes. However, when dealing with text data in an LSTM network, sentences often vary in length, some being longer or shorter than others. To utilize LSTM networks effectively, it is necessary to ensure that all inputs have the same size. This is where the concept of \"padding\" comes into play.\n",
    "\n",
    "Padding is a preprocessing technique that involves standardizing the length of sentences by defining a maximum length for each sentence and adjusting their sizes accordingly. For shorter sentences, zeros are added to achieve the desired length, while longer sentences are truncated by dropping extra words beyond the defined length.\n",
    "\n",
    "In this particular analysis, the padding process is applied with a maximum length of 88 words. Before feeding the text sequences into the LSTM network, sentences will be padded to ensure uniformity and compatibility across all inputs, enabling the model to process the data effectively. By implementing padding, the LSTM network can handle varying-length text inputs and perform sentiment analysis accurately and efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d223cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply padding to sequences.\n",
    "    \n",
    "pad = pad_sequences(enc, maxlen=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98bfdec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  85 699  13 246  42]\n"
     ]
    }
   ],
   "source": [
    "# Print any padded sequence.\n",
    "\n",
    "print(pad[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d544e",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# B4. CATEGORIES OF SENTIMENT\n",
    "\n",
    "The data will undergo sentiment classification based on customer reviews' scores, which will be categorized into two types of sentiments:\n",
    "\n",
    "- 0: Negative\n",
    "- 1: Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e18cb869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: Sentiment Score, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the total value of each score\n",
    "\n",
    "az_data['Sentiment Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a83d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scores to sentiments\n",
    "\n",
    "az_data['Customer Review'] = az_data['Customer Review'].apply(lambda z: 'Negative Feedback' \n",
    "                                                              if z == 0 else 'Positive Feedback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ae7b903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Positive Feedback\n",
       "1    Positive Feedback\n",
       "2    Positive Feedback\n",
       "3    Positive Feedback\n",
       "4    Positive Feedback\n",
       "Name: Customer Review, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Head \n",
    "\n",
    "az_data['Customer Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af526287",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# B5. STEPS TO PREPARE THE DATA\n",
    "\n",
    "- In Step 1 of the Data Preparation phase (Section B1), the customer review text is transformed to lower case to ensure uniformity in the text data.\n",
    "\n",
    "- Step 2, also part of the Data Preparation phase in Section B1, involves removing all unusual characters from the text. Non-alphabetic characters are not relevant for the Natural Language Processing (NLP) process. Only line breaks, spaces, and commas are retained.\n",
    "\n",
    "- Moving to Step 3, during the Tokenization phase in Section B2, all stop words are eliminated. These include prepositions, pronouns, articles, conjunctions, and other words that do not carry significant meaning in the context of sentiment analysis.\n",
    "\n",
    "- In Step 4, still in the Tokenization phase of Section B2, the remaining text data is tokenized. This process involves breaking down the text into individual words using a specific delimiter. Each word is then assigned a unique numeric encoding, forming the vocabulary for the entire dataset. The vocabulary is stored as an overall vocabulary list.\n",
    "\n",
    "- Step 5, which is also part of the Tokenization phase in Section B3, focuses on padding the tokenized data. This step ensures that all sentences have the same length. The maximum length for longer texts is set to 88 words, and shorter texts are padded with additional zeros to match this length.\n",
    "\n",
    "- In Step 6 (Section B4), the scores in the dataset are classified based on their sentiment types. Scores of 0 are labeled as Negative, while scores of 1 are labeled as Positive.\n",
    "\n",
    "- Step 7 involves splitting the data into predictor and response attributes. This step will be carried out in the subsequent code blocks.\n",
    "\n",
    "- Finally, in Step 8, the attributes are further divided into training and test sets. This step will also be performed in the upcoming code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9aab2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent and Dependent attribute data\n",
    "# Step 7\n",
    "\n",
    "y = az_data['Sentiment Score']\n",
    "X = pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9680f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "# Step 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84da2d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 88) (250, 88) (750,) (250,)\n"
     ]
    }
   ],
   "source": [
    "# Print the domension of the arrays\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddd90e",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# B6. PREPARED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7582a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data Set as an Excel file\n",
    "\n",
    "az_data.to_excel('amazon_preprocessed_data.xlsx', encoding = 'utf-8', index = False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d59db",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# C1. MODEL SUMMARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e900303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop lstm model \n",
    "# Reference I5\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(vc, round(length_), input_length=X.shape[1]) )\n",
    "lstm.add(SpatialDropout1D(0.25))\n",
    "lstm.add(LSTM(22, dropout=0.25, recurrent_dropout=0.25))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(1,activation='sigmoid'))\n",
    "lstm.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e16ba77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 88, 6)             10494     \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 88, 6)             0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 22)                2552      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 23        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13069 (51.05 KB)\n",
      "Trainable params: 13069 (51.05 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the model's summary\n",
    "\n",
    "print(lstm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a73e5",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# C2. NETWORK ARCHITECTURE\n",
    "\n",
    "The LSTM network in this setup comprises six distinct layers, each serving a specific purpose:\n",
    "\n",
    "1. The Embedding Layer: As the initial hidden layer, the Embedding layer plays a crucial role in learning embeddings while simultaneously training the deep learning model. It requires three essential parameters: the vocabulary size, sequence length, and the embedding length.\n",
    "\n",
    "2. The SpatialDropout1d: This layer operates on the input data, dropping entire one-dimensional feature maps instead of individual elements. The parameter utilized here is a decimal representing the dropout rate for the input units.\n",
    "\n",
    "3. LSTM Layer: As extensively explained in Section A3, this input layer is key for processing sequential data. The LSTM layer involves several parameters, including the dropout rate, the number of nodes (units), and the recurrent dropout rate.\n",
    "\n",
    "4. The Dropout Layer: Functioning as a mask, this input layer nullifies the contribution of certain neurons to the subsequent layer while leaving others unaffected. The parameter used here is a decimal that determines the dropout rate for the input units.\n",
    "\n",
    "5. The Dense Layer: Positioned as the final input layer, the Dense layer embodies a traditional fully connected neural network, where each input node is connected to every output node. The parameters applied in this layer are the number of nodes and the activation function.\n",
    "\n",
    "6. The Output Layer: In the output layer, essential parameters such as the optimizer, loss function, and metric are defined. These parameters are instrumental in generating the desired output of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a3556",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "# C3. HYPERPARAMETERS\n",
    "\n",
    "\n",
    "- Activation Functions: The decision to use the sigmoid function was influenced by the binary nature of the output. Given that the task involves binary classification, the sigmoid activation function is well-suited for mapping the final predictions to probabilities between 0 and 1.\n",
    "\n",
    "- Number of Nodes per Layer: To accommodate the sigmoid activation function in the dense layer, a single node was selected. As for the LSTM layer, I opted for 22 nodes, which represents a quarter of the number of nodes used in the Embedding Layer. This choice aims to strike a balance between model complexity and capturing relevant patterns in the data.\n",
    "\n",
    "- Loss Function: The adoption of binary crossentropy as the loss function is a consequence of the binary classification nature of the problem. This particular loss function is well-established for binary classification tasks, facilitating the model's ability to optimize and make accurate predictions.\n",
    "\n",
    "- Optimizer: For its high efficiency and compatibility with LSTM networks, the Adam optimizer was chosen. Adam is an adaptive learning rate optimization algorithm that effectively updates model weights and helps converge faster during training.\n",
    "\n",
    "- Stopping Criteria: The stopping criteria for the training process involves monitoring the loss function of the validation set for five consecutive epochs. Once this criterion is met, the training process concludes. The implementation of this stopping criteria can be found in Section D1.\n",
    "\n",
    "- Evaluation Metric: In this model, the standard evaluation metric used is accuracy. Accuracy is a reliable measure to assess the performance of the model, as it quantifies the percentage of correct predictions compared to the actual labels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6e305",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# D1. STOPPING CRITERIA\n",
    "\n",
    "Using an excessive number of epochs during model training can lead to overfitting, causing the model to become overly specialized to the training dataset and perform poorly on unseen data. Conversely, too few epochs may result in an underfit model that fails to capture the underlying patterns in the data. To address these issues, the concept of \"early stopping\" is employed.\n",
    "\n",
    "Early stopping is a technique that involves setting a large number of training epochs and continuously monitoring the model's performance on a separate validation dataset. As the training progresses, if the model's performance on the validation dataset ceases to improve or starts to degrade, the training process is halted before completing all the epochs. This helps prevent overfitting and ensures that the model is stopped at the point where it demonstrates the best generalization ability on unseen data (Brownlee, 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1cbc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Criteria\n",
    "\n",
    "stop_ = EarlyStopping(mode='min', monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9e496",
   "metadata": {},
   "source": [
    "The patience parameter was set to five in the above code execution implying that if there is a loss of accuracy in five successive epochs, the process will have to end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c7427",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# D2. TRAINING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7039c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 9s 144ms/step - loss: 0.6930 - accuracy: 0.4964 - val_loss: 0.6927 - val_accuracy: 0.5372\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 2s 106ms/step - loss: 0.6912 - accuracy: 0.6228 - val_loss: 0.6921 - val_accuracy: 0.5532\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 2s 103ms/step - loss: 0.6893 - accuracy: 0.6014 - val_loss: 0.6907 - val_accuracy: 0.5798\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 2s 108ms/step - loss: 0.6845 - accuracy: 0.6637 - val_loss: 0.6872 - val_accuracy: 0.6436\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.6731 - accuracy: 0.7740 - val_loss: 0.6789 - val_accuracy: 0.6277\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 2s 109ms/step - loss: 0.6494 - accuracy: 0.6868 - val_loss: 0.6706 - val_accuracy: 0.5798\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 2s 110ms/step - loss: 0.6155 - accuracy: 0.7794 - val_loss: 0.6424 - val_accuracy: 0.7394\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.5445 - accuracy: 0.8399 - val_loss: 0.6085 - val_accuracy: 0.7394\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 2s 107ms/step - loss: 0.4721 - accuracy: 0.8897 - val_loss: 0.5751 - val_accuracy: 0.7287\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 2s 113ms/step - loss: 0.3904 - accuracy: 0.8950 - val_loss: 0.5426 - val_accuracy: 0.7394\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 2s 112ms/step - loss: 0.3085 - accuracy: 0.9253 - val_loss: 0.5493 - val_accuracy: 0.7234\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.2638 - accuracy: 0.9270 - val_loss: 0.5203 - val_accuracy: 0.7447\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.2086 - accuracy: 0.9431 - val_loss: 0.5497 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.1924 - accuracy: 0.9466 - val_loss: 0.5353 - val_accuracy: 0.7340\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 2s 106ms/step - loss: 0.1714 - accuracy: 0.9662 - val_loss: 0.5530 - val_accuracy: 0.7394\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 2s 111ms/step - loss: 0.1480 - accuracy: 0.9537 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 2s 110ms/step - loss: 0.1123 - accuracy: 0.9733 - val_loss: 0.5688 - val_accuracy: 0.7447\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Model Training \n",
    "# Reference I5\n",
    "\n",
    "trn = lstm.fit(X_train,y_train, validation_split=0.25, batch_size=30, callbacks=[stop_], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac51d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy: 92.40%\n",
      "Test Data Accuracy: 76.80%\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "_, acc_train = lstm.evaluate(X_train, y_train, verbose=0)\n",
    "_, acc_test = lstm.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Training Data Accuracy: {0:.2f}%'.format(acc_train*100))\n",
    "print('Test Data Accuracy: {0:.2f}%'.format(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f33d81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model training history\n",
    "\n",
    "plt.plot(trn.history['loss'], label='Train Data')\n",
    "plt.plot(trn.history['val_loss'], label='Test Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780a362",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# D3. FIT\n",
    "\n",
    "Based on the accuracy results presented in Section D2, there are indications that the model might be overfitting. Specifically, the model achieves an impressive accuracy of around 92.40% on the training data, but the accuracy drops to approximately 76.80% on the test data. Such a significant disparity between training and test accuracies suggests that the model is not generalizing well to unseen data, despite efforts made to prevent overfitting.\n",
    "\n",
    "In Section D1, a stopping criteria was implemented to prevent overfitting. This criteria allows for the specification of a large number of training epochs but halts the training process if the model's performance does not improve on a hold-out validation dataset. Additionally, both Spatial_Dropout1d and Dropout layers were included in the model architecture. These layers randomly ignore certain nodes during training, preventing the model from relying too heavily on specific nodes and reducing the likelihood of inheriting mistakes from previous nodes.\n",
    "\n",
    "However, despite these measures, the model's performance on the test data indicates the possibility of overfitting. It is essential to further investigate and fine-tune the model to enhance its generalization capabilities and improve its performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3c557",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# D4. PREDICTIVE ACCURACY\n",
    "The classification report and heatmap below provide insights into the model's predictive accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98a2bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Acquire predicted test values\n",
    "\n",
    "y_pred = lstm.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d7fc52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.79      0.77       126\n",
      "           0       0.78      0.75      0.76       124\n",
      "\n",
      "    accuracy                           0.77       250\n",
      "   macro avg       0.77      0.77      0.77       250\n",
      "weighted avg       0.77      0.77      0.77       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model's Classification Report\n",
    "\n",
    "rep = classification_report(y_test,y_pred,labels=[1,0])\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab56628c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "mtrx = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mtrx/np.sum(mtrx), annot=True, fmt=' .2%', cmap='Accent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc8e58",
   "metadata": {},
   "source": [
    "Based on the findings in the above report, we can infer that the model demonstrates reasonably accurate predictions concerning user sentiments. However, my confidence in the model is not very high due to the notable probability of making incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b5b9f8",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# E. CODE\n",
    "\n",
    "In the code blocks above, you can find all the codes used to save the trained neural network within the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342bb99",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# F. FUNCTIONALITY\n",
    "In terms of functionality, this neural network model exhibits both positive and negative aspects. On the negative side, the model's accuracy is a concern, as it tends to achieve very high predictions on the training data but shows a noticeable drop in accuracy on the test data, although it still performs reasonably well. Consequently, a considerable number of reviews may be misclassified with respect to their sentiment.\n",
    "\n",
    "On the positive side, the model demonstrates remarkable speed during training. This can be attributed to its simple architecture and the relatively small dataset used for this analysis. As a result, the model's training process completes within a few seconds, implying that there are no significant processing costs, and all results are generated promptly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb0f6e",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "# G. RECOMMENDATIONS\n",
    "\n",
    "I would advise Amazon stakeholders to conduct further analysis on this data to develop a more efficient model capable of making nearly perfect predictions on user sentiments. To achieve this, they can explore the following approaches:\n",
    "\n",
    "1. Hyperparameter Tuning: Experiment with different hyperparameters such as learning rate, batch size, number of epochs, and dropout rates. By systematically varying these parameters, the model's performance can be fine-tuned to achieve better accuracy on both training and test datasets.\n",
    "\n",
    "2. Cross-Validation: Employ cross-validation techniques to ensure the model's generalization performance. This can help detect overfitting issues and provide a more realistic estimate of the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5eea3",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# H. REPORTING\n",
    "\n",
    "This document was produced using the Jupyter Notebook environment, and then converted to and reported in a PDF format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c92f8a",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# I. SOURCES FOR THIRD-PARTY CODE\n",
    "1: https://stackoverflow.com/questions/41610543/corpora-stopwords-not-found-when-import-nltk-library\n",
    "\n",
    "2: https://www.geeksforgeeks.org/how-to-read-text-files-with-pandas/\n",
    "\n",
    "3: https://stackoverflow.com/questions/22520932/python-remove-all-non-alphabet-chars-from-string\n",
    "\n",
    "4: https://stackabuse.com/removing-stop-words-from-strings-in-python/\n",
    "\n",
    "5: https://www.analyticsvidhya.com/blog/2021/06/natural-language-processing-sentiment-analysis-using-lstm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab6c82",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# J. SOURCES\n",
    "1: Intellipaat (2022, February 5). What is LSTM? Introduction to Long Short Term Memory. Retrieved July 22 2023 at  https://intellipaat.com/blog/what-is-lstm/\n",
    "\n",
    "2: Perry T (2021,  February 1). What is Tokenization in Natural Language Processing (NLP)?. Retrieved July 22 2023 at https://www.machinelearningplus.com/nlp/what-is-tokenization-in-natural-language-processing/\n",
    "\n",
    "3: Brownlee J (2018, December 10). Use Early Stopping to Halt the Training of Neural Networks At the Right Time. Retrieved July 22 2023 at https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
